# Documentation du Benchmark et √âvaluation des Strat√©gies

Ce r√©pertoire contient l'ensemble des protocoles, des donn√©es de test et des outils d'analyse ayant permis de comparer et de s√©lectionner la meilleure architecture technique pour l'assistant FAQ de la **Communaut√© de Communes Val de Loire Num√©rique**.

![Description strategie evaluation](InfographieBENCHMARK.png)
---

## üìä Objectif de l'√âvaluation

L'objectif est de comparer objectivement trois approches de **Question-Answering** pour automatiser les r√©ponses administratives, tout en garantissant la fiabilit√© des informations fournies aux citoyens.

---

## üîç Strat√©gies Compar√©es

- **Strat√©gie A (LLM Seul)** : Utilisation directe de Mistral 7B v0.2 Instruct avec un prompt syst√®me.
- **Strat√©gie B (RAG - Recherche + G√©n√©ration)** : Recherche s√©mantique dans la base FAQ suivie d'une g√©n√©ration contextuelle par le LLM. **Solution retenue**.
- **Strat√©gie C (Q&A Extractif)** : Recherche s√©mantique coupl√©e √† un mod√®le extractif (CamemBERT) qui isole la r√©ponse exacte dans le texte.

---

## üìè M√©triques et Pond√©ration

Chaque strat√©gie a √©t√© √©valu√©e selon cinq crit√®res critiques, agr√©g√©s dans un score global pond√©r√© :

| Crit√®re          | Description                                                                 | Poids |
|------------------|-----------------------------------------------------------------------------|-------|
| Exactitude       | Pourcentage de r√©ponses correctes par rapport aux faits r√©els.              | 30%   |
| Pertinence       | Qualit√© et ad√©quation de la r√©ponse √† la question pos√©e.                   | 20%   |
| Fid√©lit√©         | Absence d'informations invent√©es ou erron√©es (non-hallucination).           | 20%   |
| Latence          | Temps de r√©ponse moyen (cible < 2 secondes).                                | 15%   |
| Complexit√©       | Facilit√© de maintenance et √©volutivit√© de la solution.                      | 15%   |

---

## üß™ Protocole d'√âvaluation

1. **Golden Set** : Un jeu de test de 30 questions repr√©sentatives des th√©matiques citoyennes (√©tat civil, urbanisme, etc.) a √©t√© constitu√©.
2. **√âvaluation Automatis√©e** : Utilisation du framework **RAGAS** (LLM-as-a-judge) pour mesurer la fid√©lit√© et la pertinence de mani√®re industrielle.

---

## üìà R√©sultats et Analyse

Les analyses montrent que la **Strat√©gie B (RAG)** offre le meilleur √©quilibre :
- **Exactitude excellente** : Utilise la base FAQ comme source unique de v√©rit√©.
- **Hallucinations quasi nulles** : Le LLM est contraint par le contexte fourni.
- **Performance globale** : Elle obtient le score pond√©r√© le plus √©lev√© lors des tests comparatifs.

√Ä l'inverse :
- La **Strat√©gie A** est √©cart√©e en raison de son taux √©lev√© d'hallucinations.
- La **Strat√©gie C** est rejet√©e pour son manque de fluidit√© conversationnelle.

---

## üõ†Ô∏è Outils d'Analyse

Pour reproduire ou visualiser ces r√©sultats, plusieurs notebooks **Marimo** sont disponibles :
- [`notebooks/automated_benchmark.py`](./notebooks/automated_benchmark.py) : G√©n√©ration des graphiques radar et comparaison des m√©triques RAGAS.

> **Note** : Les r√©sultats d√©taill√©s sont stock√©s au format Parquet.
